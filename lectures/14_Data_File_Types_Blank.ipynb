{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bce3d0a",
   "metadata": {},
   "source": [
    "# Data File Types\n",
    "\n",
    "Data can come in many different forms and, for our purposes, can be stored in various formats. In this notebook we will touch on some of the different file types you may encounter.\n",
    "\n",
    "## What we will accomplish\n",
    "\n",
    "In this notebook we will discuss the following file types:\n",
    "- Basic text or `.txt` files,\n",
    "- Comma separated values or `.csv` files,\n",
    "- Tab separated values or `.tsv` files,\n",
    "- JavaScript object notation or `.json` files,\n",
    "- Columnar data, or `.parquete` files,\n",
    "- Zipped drives and\n",
    "- Compressed tar files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d83057",
   "metadata": {},
   "source": [
    "## Uncompressed files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569dc1d4",
   "metadata": {},
   "source": [
    "### Basic .txt files\n",
    "\n",
    "A file that ends in `.txt` is a text file. This is a file that contains sequences of characters (letters, numbers, special characters, etc.) that is readable by a computer. To see an example of this file type open `sample_text_file.txt` from the `data` folder.\n",
    "\n",
    "These files are often used to store text based data like transcripts, essays, raw (meaning no meta-data) tweets and more. You can open and read these files using `open()` as described in <a href=\"Reading and Writing to File.ipynb\">Reading and Writing to File</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1191c339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello this is a sample text file :).\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/sample_text_file.txt\", \"r\") as file:\n",
    "    print(file.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17dc069",
   "metadata": {},
   "source": [
    "### .csv files\n",
    "\n",
    "A `.csv` or comma separated values file, sometimes called a <i>comma delimited file</i>, is a file containing data organized into columns and rows. Each column in the file is separated by a `,` and each row is placed on a new line within the file. We can think of these as a table of data represented in a text file. For an example see `sample_csv_file.csv` in the `data` folder.\n",
    "\n",
    "\n",
    "While we can also read these in using `open`, it is easier to use something like `pandas`. See the code below where we read in `sample_csv_file.csv` using the `.read_csv()` function, <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\">https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3bd3242",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _multiarray_umath: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _multiarray_umath: The specified module could not be found."
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy._core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## importing pandas as pd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lmwhe\\anaconda3\\envs\\python-bootcamp\\Lib\\site-packages\\pandas\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ArrowDtype,\n\u001b[0;32m     52\u001b[0m     Int8Dtype,\n\u001b[0;32m     53\u001b[0m     Int16Dtype,\n\u001b[0;32m     54\u001b[0m     Int32Dtype,\n\u001b[0;32m     55\u001b[0m     Int64Dtype,\n\u001b[0;32m     56\u001b[0m     UInt8Dtype,\n\u001b[0;32m     57\u001b[0m     UInt16Dtype,\n\u001b[0;32m     58\u001b[0m     UInt32Dtype,\n\u001b[0;32m     59\u001b[0m     UInt64Dtype,\n\u001b[0;32m     60\u001b[0m     Float32Dtype,\n\u001b[0;32m     61\u001b[0m     Float64Dtype,\n\u001b[0;32m     62\u001b[0m     CategoricalDtype,\n\u001b[0;32m     63\u001b[0m     PeriodDtype,\n\u001b[0;32m     64\u001b[0m     IntervalDtype,\n\u001b[0;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     66\u001b[0m     StringDtype,\n\u001b[0;32m     67\u001b[0m     BooleanDtype,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     NA,\n\u001b[0;32m     70\u001b[0m     isna,\n\u001b[0;32m     71\u001b[0m     isnull,\n\u001b[0;32m     72\u001b[0m     notna,\n\u001b[0;32m     73\u001b[0m     notnull,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     Index,\n\u001b[0;32m     76\u001b[0m     CategoricalIndex,\n\u001b[0;32m     77\u001b[0m     RangeIndex,\n\u001b[0;32m     78\u001b[0m     MultiIndex,\n\u001b[0;32m     79\u001b[0m     IntervalIndex,\n\u001b[0;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     81\u001b[0m     DatetimeIndex,\n\u001b[0;32m     82\u001b[0m     PeriodIndex,\n\u001b[0;32m     83\u001b[0m     IndexSlice,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     NaT,\n\u001b[0;32m     86\u001b[0m     Period,\n\u001b[0;32m     87\u001b[0m     period_range,\n\u001b[0;32m     88\u001b[0m     Timedelta,\n\u001b[0;32m     89\u001b[0m     timedelta_range,\n\u001b[0;32m     90\u001b[0m     Timestamp,\n\u001b[0;32m     91\u001b[0m     date_range,\n\u001b[0;32m     92\u001b[0m     bdate_range,\n\u001b[0;32m     93\u001b[0m     Interval,\n\u001b[0;32m     94\u001b[0m     interval_range,\n\u001b[0;32m     95\u001b[0m     DateOffset,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     to_numeric,\n\u001b[0;32m     98\u001b[0m     to_datetime,\n\u001b[0;32m     99\u001b[0m     to_timedelta,\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     Flags,\n\u001b[0;32m    102\u001b[0m     Grouper,\n\u001b[0;32m    103\u001b[0m     factorize,\n\u001b[0;32m    104\u001b[0m     unique,\n\u001b[0;32m    105\u001b[0m     value_counts,\n\u001b[0;32m    106\u001b[0m     NamedAgg,\n\u001b[0;32m    107\u001b[0m     array,\n\u001b[0;32m    108\u001b[0m     Categorical,\n\u001b[0;32m    109\u001b[0m     set_eng_float_format,\n\u001b[0;32m    110\u001b[0m     Series,\n\u001b[0;32m    111\u001b[0m     DataFrame,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32mc:\\Users\\lmwhe\\anaconda3\\envs\\python-bootcamp\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\lmwhe\\anaconda3\\envs\\python-bootcamp\\Lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: numpy._core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "## importing pandas as pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28cb142",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_table = pd.read_csv(\"../data/sample_csv_file.csv\")\n",
    "print(type(csv_table))\n",
    "print(csv_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de878e14",
   "metadata": {},
   "source": [
    "### .tsv files\n",
    "\n",
    "A `.tsv` or tab separated values file, sometimes called <i>tab delimited file</i>, is identical to a `.csv` file where the columns of data are separated with tabs or `\\t` characters. For an example see `sample_tsv_file.csv` in the `data` folder.\n",
    "\n",
    "These can be read in using the `.read_table()` function in `pandas`, <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.read_table.html\">https://pandas.pydata.org/docs/reference/api/pandas.read_table.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53fa42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_table(\"../data/sample_tsv_file.tsv\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8692650b",
   "metadata": {},
   "source": [
    "### JSON files\n",
    "\n",
    "A `.json` or JavaScript object notation file is a file type that stores data the way it is typically transported between applications and servers online. The structure of the JSON format is quite similar to that of a Python dictionary (`dict`), as we will soon see. To look at an example open `miserables.json`, which is a JSON file taken from the d3.js GitHub repository, <a href=\"https://github.com/d3/d3-plugins/blob/master/graph/data/miserables.json\">https://github.com/d3/d3-plugins/blob/master/graph/data/miserables.json</a>. This file stores the characters from the novel <u>Les Miserables</u> by Victor Hugo as a series of nodes and links in order to describe a character network. Here each node is a character in the novel and a link between A and B represents the number of chapters in which characters A and B both appear.\n",
    "\n",
    "We can load in this file using `open()` and the `json` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import json\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dea8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \n",
    "\n",
    "## we can load in the data with json.load()\n",
    "les_mis = \n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## As we can see the data is read in as a dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb717400",
   "metadata": {},
   "outputs": [],
   "source": [
    "## see :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c65ab68",
   "metadata": {},
   "source": [
    "### Parquet files\n",
    "\n",
    "Parquet files (`.parquet`) present a different way of storing data that can siginificantly improve on the query speed, memory requirements, and some calculations when compared to other file types like `.csv` and `.tsv`.\n",
    "\n",
    "File types like `.csv` and `.tsv` are row-based data storage approaches, that is each row represents an observation and each column a variable. Parquet takes what's known as a columnar approach to storing data. In columnar data storage each row represents a variable and each column represents an observation.\n",
    "\n",
    "For example `sample_csv_file.csv` looks like this in storage:\n",
    "\n",
    "`column_1, column_2, column_3`\n",
    "\n",
    "`1, 'a', 8`\n",
    "\n",
    "`2, 'b', 5`\n",
    "\n",
    "`3, 'c', 3`\n",
    "\n",
    "`4, 'd', 2`\n",
    "\n",
    "`5, 'e', 7`.\n",
    "\n",
    "\n",
    "The equivalent `.parquet` file would theoretically look like this in storage:\n",
    "\n",
    "\n",
    "`column_1: 1, 2, 3, 4, 5`\n",
    "\n",
    "`column_2: 'a', 'b', 'c', 'd', 'e'`\n",
    "\n",
    "`column_3: 8, 5, 3, 2, 7`\n",
    "\n",
    "however, we are unable to open a `.parquet` file with a text editor and see such a file.\n",
    "\n",
    "Columnar formats have advantages in storage of large data files because they can be encoded in ways that row-based formats cannot that greatly reduce the amount of data that needs to be stored.\n",
    "\n",
    "For our purposes, we can read in a `.parquet` file with `pandas` `read_parquet` function, <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html\">https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html</a>. Note that when we read in a `.parquet` file in this way, it is converted to the standard row-based format of a `pandas` `DataFrame`. Note, that in order to use `read_parquet` you have to have `pyarrow` or `fastparquet` installed:\n",
    "- `pyarrow` installation instructions: <a href=\"https://arrow.apache.org/docs/python/install.html\">https://arrow.apache.org/docs/python/install.html</a>\n",
    "- `fastparquet` installation instructions: <a href=\"https://github.com/dask/fastparquet/#installation\">https://github.com/dask/fastparquet/#installation</a>.\n",
    "\n",
    "If you are unsure on how to install a python package, you cand see more using the python package installation guide on the python prep Erd&#337;s Institute website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c7e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d86efeb",
   "metadata": {},
   "source": [
    "The parquet format is actually a little more complicated than what was presented above, but that is a good introduction. If you would like to learn more about `.parquet` files check out the optional notebook, <a href=\"Parquet Files (Optional).ipynb\">Parquet Files (Optional)</a>.\n",
    "\n",
    "## Compressed file types\n",
    "\n",
    "If you have a particularly large set of data, perhaps spanning multiple files, it is likely that you will initially recieve it in a compressed format. In order to access the data you will first need to uncompress the files. Let's review how to do so for two of the most popular compressed file types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e74df4",
   "metadata": {},
   "source": [
    "### Zipped files\n",
    "\n",
    "You have most likely encountered these before. Zipped files are those that end with `.zip`. To uncompress these you can do the following:\n",
    "\n",
    "#### MacOS\n",
    "\n",
    "Double click on the `.zip` file in the Finder.\n",
    "\n",
    "#### Windows\n",
    "\n",
    "Locate the `.zip` file and double click.\n",
    "\n",
    "#### Linux\n",
    "\n",
    "To uncompress a `.zip` file on a Linux machine follow the instructions at this post, <a href=\"https://linuxize.com/post/how-to-unzip-files-in-linux/\">https://linuxize.com/post/how-to-unzip-files-in-linux/</a>.\n",
    "\n",
    "You can practice using the `example.zip` file in the `data` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e36015",
   "metadata": {},
   "source": [
    "### Tar files\n",
    "\n",
    "Another very popular compression file type is known as a <i>tar file</i> or <i>tarball</i>. These files end in a `.tar` or `.tar.gz`.\n",
    "\n",
    "These can be uncompressed like so:\n",
    "\n",
    "#### MacOS\n",
    "\n",
    "You can double click the file, or execute `tar -xzf file_name.tar.gz` or `tar -xf file_name.tar` in the command prompt, depending on how the filename ends. Note, this assumes you are in the correct directory on your computer.\n",
    "\n",
    "#### Windows\n",
    "\n",
    "Follow instructions found on <a href=\"https://www.7-zip.org/\">https://www.7-zip.org/</a>. This piece of software will enable you to extract the data in a tar file.\n",
    "\n",
    "#### Linux\n",
    "\n",
    "Follow the command prompt instructions under the MacOS header.\n",
    "\n",
    "\n",
    "You can practice this using the `example.tar.gz` file in the `data` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0671ca",
   "metadata": {},
   "source": [
    "We now know of the most common data file types. Let's move on and learn how we might find some data files of our own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee5b27",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2023.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbcaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
